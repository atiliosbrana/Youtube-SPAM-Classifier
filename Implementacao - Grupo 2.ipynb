{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YouTube Spam Collection v. 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grupo 2\n",
    "Alberto Atilio Sbrana Junior\n",
    "<br>\n",
    "Luiz Barreto Pedro de Alcântara\n",
    "<br>\n",
    "Priscila Portela Costa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trata-se de um problema de classificação binária sobre comentários de vídeos no Youtube.\n",
    "<br>\n",
    "Há no total 5 arquivos, separados por artista:\n",
    "- Psy\n",
    "- Katy Perry\n",
    "- LMFAO\n",
    "- Eminem\n",
    "- Shakira"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import svmutil\n",
    "from svmutil import svm_read_problem\n",
    "from svmutil import svm_problem\n",
    "from svmutil import svm_parameter\n",
    "from svmutil import svm_train\n",
    "from svmutil import svm_predict\n",
    "from svmutil import svm_save_model\n",
    "import matplotlib.pyplot as plt #visualização\n",
    "from ML_library import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_psy = pd.read_csv('Youtube 01-comments Psy.csv')\n",
    "df_kat = pd.read_csv('Youtube 04-comments KatyPerry.csv')\n",
    "df_lma = pd.read_csv('Youtube 07-comments LMFAO.csv')\n",
    "df_emi = pd.read_csv('Youtube 08-comments Eminem.csv')\n",
    "df_sha = pd.read_csv('Youtube 09-comments Shakira.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COMMENT_ID</th>\n",
       "      <th>AUTHOR</th>\n",
       "      <th>DATE</th>\n",
       "      <th>CONTENT</th>\n",
       "      <th>CLASS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LZQPQhLyRh80UYxNuaDWhIGQYNQ96IuCg-AYWqNPjpU</td>\n",
       "      <td>Julius NM</td>\n",
       "      <td>2013-11-07T06:20:48</td>\n",
       "      <td>Huh, anyway check out this you[tube] channel: ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LZQPQhLyRh_C2cTtd9MvFRJedxydaVW-2sNg5Diuo4A</td>\n",
       "      <td>adam riyati</td>\n",
       "      <td>2013-11-07T12:37:15</td>\n",
       "      <td>Hey guys check out my new channel and our firs...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LZQPQhLyRh9MSZYnf8djyk0gEF9BHDPYrrK-qCczIY8</td>\n",
       "      <td>Evgeny Murashkin</td>\n",
       "      <td>2013-11-08T17:34:21</td>\n",
       "      <td>just for test I have to say murdev.com</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>z13jhp0bxqncu512g22wvzkasxmvvzjaz04</td>\n",
       "      <td>ElNino Melendez</td>\n",
       "      <td>2013-11-09T08:28:43</td>\n",
       "      <td>me shaking my sexy ass on my channel enjoy ^_^ ﻿</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>z13fwbwp1oujthgqj04chlngpvzmtt3r3dw</td>\n",
       "      <td>GsMega</td>\n",
       "      <td>2013-11-10T16:05:38</td>\n",
       "      <td>watch?v=vtaRGgvGtWQ   Check this out .﻿</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    COMMENT_ID            AUTHOR  \\\n",
       "0  LZQPQhLyRh80UYxNuaDWhIGQYNQ96IuCg-AYWqNPjpU         Julius NM   \n",
       "1  LZQPQhLyRh_C2cTtd9MvFRJedxydaVW-2sNg5Diuo4A       adam riyati   \n",
       "2  LZQPQhLyRh9MSZYnf8djyk0gEF9BHDPYrrK-qCczIY8  Evgeny Murashkin   \n",
       "3          z13jhp0bxqncu512g22wvzkasxmvvzjaz04   ElNino Melendez   \n",
       "4          z13fwbwp1oujthgqj04chlngpvzmtt3r3dw            GsMega   \n",
       "\n",
       "                  DATE                                            CONTENT  \\\n",
       "0  2013-11-07T06:20:48  Huh, anyway check out this you[tube] channel: ...   \n",
       "1  2013-11-07T12:37:15  Hey guys check out my new channel and our firs...   \n",
       "2  2013-11-08T17:34:21             just for test I have to say murdev.com   \n",
       "3  2013-11-09T08:28:43   me shaking my sexy ass on my channel enjoy ^_^ ﻿   \n",
       "4  2013-11-10T16:05:38            watch?v=vtaRGgvGtWQ   Check this out .﻿   \n",
       "\n",
       "   CLASS  \n",
       "0      1  \n",
       "1      1  \n",
       "2      1  \n",
       "3      1  \n",
       "4      1  "
      ]
     },
     "execution_count": 465,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_psy.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tratamento de dados - Occurrency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [],
   "source": [
    "#origem do video\n",
    "df_psy['origin'] = 'psy'\n",
    "df_kat['origin'] = 'kat'\n",
    "df_lma['origin'] = 'lma'\n",
    "df_emi['origin'] = 'emi'\n",
    "df_sha['origin'] = 'sha'\n",
    "\n",
    "#junção dos datasets\n",
    "df_start = df_psy.append([df_kat, df_lma, df_emi, df_sha]).reset_index(drop=True)\n",
    "\n",
    "#criação de novas colunas: ano, data e has_date (booleana, para o caso do dataset do eminem)\n",
    "df_start['DATE'] = pd.to_datetime(df_start['DATE'],infer_datetime_format=True)\n",
    "df_start['comment_year'] = df_start['DATE'].dt.year\n",
    "df_start['comment_hour'] = df_start['DATE'].dt.hour\n",
    "df_start['has_date'] = np.where(df_start['comment_year'] == 1969, False, True)\n",
    "df_start['comment_len'] = df_start['CONTENT'].str.len()\n",
    "\n",
    "#apagar colunas\n",
    "df_start.drop(['DATE', 'COMMENT_ID'], axis=1, inplace=True)\n",
    "df_start.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUTHOR</th>\n",
       "      <th>CONTENT</th>\n",
       "      <th>CLASS</th>\n",
       "      <th>origin</th>\n",
       "      <th>comment_year</th>\n",
       "      <th>comment_hour</th>\n",
       "      <th>has_date</th>\n",
       "      <th>comment_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Julius NM</td>\n",
       "      <td>Huh, anyway check out this you[tube] channel: ...</td>\n",
       "      <td>1</td>\n",
       "      <td>psy</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>True</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>adam riyati</td>\n",
       "      <td>Hey guys check out my new channel and our firs...</td>\n",
       "      <td>1</td>\n",
       "      <td>psy</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>True</td>\n",
       "      <td>166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Evgeny Murashkin</td>\n",
       "      <td>just for test I have to say murdev.com</td>\n",
       "      <td>1</td>\n",
       "      <td>psy</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>True</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ElNino Melendez</td>\n",
       "      <td>me shaking my sexy ass on my channel enjoy ^_^ ﻿</td>\n",
       "      <td>1</td>\n",
       "      <td>psy</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>True</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GsMega</td>\n",
       "      <td>watch?v=vtaRGgvGtWQ   Check this out .﻿</td>\n",
       "      <td>1</td>\n",
       "      <td>psy</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>True</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             AUTHOR                                            CONTENT  CLASS  \\\n",
       "0         Julius NM  Huh, anyway check out this you[tube] channel: ...      1   \n",
       "1       adam riyati  Hey guys check out my new channel and our firs...      1   \n",
       "2  Evgeny Murashkin             just for test I have to say murdev.com      1   \n",
       "3   ElNino Melendez   me shaking my sexy ass on my channel enjoy ^_^ ﻿      1   \n",
       "4            GsMega            watch?v=vtaRGgvGtWQ   Check this out .﻿      1   \n",
       "\n",
       "  origin  comment_year  comment_hour  has_date  comment_len  \n",
       "0    psy        2013.0           6.0      True           56  \n",
       "1    psy        2013.0          12.0      True          166  \n",
       "2    psy        2013.0          17.0      True           38  \n",
       "3    psy        2013.0           8.0      True           48  \n",
       "4    psy        2013.0          16.0      True           39  "
      ]
     },
     "execution_count": 467,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_start.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dicionario pra substituicao de contracoes, girias, typos, stemming\n",
    "word_dict = {\n",
    "    'pls': 'please',\n",
    "    'plz': 'please',\n",
    "    'plizz': 'please',\n",
    "    'pplease': 'please',\n",
    "    'pleassssssssssssssss': 'please',\n",
    "    'dis': 'this',\n",
    "    'yt': 'youtube',\n",
    "    'you[tube]': 'youtube',\n",
    "    'instagraml': 'instagram',\n",
    "    'facebook-page': 'facebook',\n",
    "    'wiredo': 'wierdo',\n",
    "    'vid': 'video',\n",
    "    'videoeo': 'video',\n",
    "    'sub': 'subscribe',\n",
    "    'thx': 'thanks',\n",
    "    'suscribe': 'subscribe',\n",
    "    'allot': 'lot',\n",
    "    'wat': 'what',\n",
    "    'should.d': 'should',\n",
    "    'ilove': 'love',\n",
    "    'likesubscribescribe': 'subscribe',\n",
    "    'subscribescribe': 'subscribe',\n",
    "    'anyoutubehing' : 'youtube',\n",
    "    'itttttttt': 'it',\n",
    "    'im': 'i',\n",
    "    'channelthanks': 'channel'\n",
    "}\n",
    "\n",
    "#lista de stop workds da biblioteca NLTK\n",
    "stop_words = ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves',\n",
    "              'you','you are','you have','you will',\"you had\",'your','yours','yourself','yourselves',\n",
    "              'he','him','his','himself','she',\"she is\",'her','hers','herself','it',\"it is\",'its',\n",
    "              'itself','they','them','their','theirs','themselves','what','which','who','whom','this','that',\n",
    "              \"that will\",'these','those','am','is','are','was','were','be','been','being','have',\n",
    "              'has','had','having','do','does','did','doing','a','an','the','and','but','if',\n",
    "              'or','because','as','until','while','of','at','by','for','with','about','against','between',\n",
    "              'into','through','during','before','after','above','below','to','from','up','down',\n",
    "              'in','out','on','off','over','under','again','further','then','once','here','there',\n",
    "              'when','where','why','how','all','any','both','each','few','more','most','other',\n",
    "              'some','such','no','nor','not','only','own','same','so','than','too','very','s','t','can',\n",
    "              'will','just','don',\"do not\",'should',\"should have\",'now','d','ll','m','o','re','ve','y','ain',\n",
    "              'aren',\"are not\",'couldn',\"could not\",'didn',\"did not\",'doesn',\"does not\",'hadn',\"had not\",\n",
    "              'hasn',\"has not\",'haven',\"have not\",'isn',\"is not\",'ma','mightn',\"might not\",'mustn',\"must not\",\n",
    "              'needn',\"need not\",'shan',\"shall not\",'shouldn',\"should not\",'wasn',\"was not\",'weren',\"were not\",\n",
    "              'won',\"will not\",'wouldn',\"would not\", 'ill']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trata_dados(df, treatment_type):\n",
    "    \n",
    "    #transformação trigonometrica da coluna hour\n",
    "    df['sin_time'] = np.sin(2*np.pi*df['comment_hour']/24)\n",
    "    df['cos_time'] = np.cos(2*np.pi*df['comment_hour']/24)\n",
    "        \n",
    "    #criar dummy pra cada origem\n",
    "    df = pd.get_dummies(df, columns=['origin', 'has_date'])\n",
    "    \n",
    "    #novas feature\n",
    "    df['has_www'] = df['CONTENT'].str.contains(pat = 'www') \n",
    "    df['has_http'] = df['CONTENT'].str.contains(pat = 'http')\n",
    "    df['has_link'] = df['CONTENT'].str.contains(pat = 'watch\\?v=')   \n",
    "    df['has_website'] = (df['has_www'] == True) | (df['has_http'] == True) | (df['has_link'] == True)\n",
    "    \n",
    "    #tratamento de texto\n",
    "    df.drop('AUTHOR', axis=1, inplace=True)\n",
    "    df['CONTENT'] = df['CONTENT'].str.lower()\n",
    "    \n",
    "    column_list = []\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        content = row['CONTENT']\n",
    "        \n",
    "        #retirar emojis e caracteres especiais\n",
    "        regular_characters = \"abcdefghijklmnopqrstuvwxyz \" \n",
    "        content = ''.join(c for c in content if c in regular_characters)\n",
    "        \n",
    "        #transfoma texto em lista de palavras:\n",
    "        content = content.split()\n",
    "                \n",
    "        #substituir contracoes de palavras\n",
    "        for k, v in word_dict.items():\n",
    "            content = [c.replace(k, v) for c in content]\n",
    "        \n",
    "        #remover stop words\n",
    "        for sw in stop_words:\n",
    "            content = [c for c in content if sw != c]\n",
    "        \n",
    "        column_list.append(content)\n",
    "        \n",
    "    column_list = [word for word in column_list if len(word) > 0]\n",
    " \n",
    "    df['CONTENT'] = pd.Series(column_list)\n",
    "    \n",
    "    df.dropna(axis=0, subset=['CONTENT'], inplace=True)\n",
    "    df = df[df['CONTENT'] != '[]']\n",
    "    \n",
    "    #transformar cada palavra em uma feature\n",
    "    columns = []\n",
    "    for sublist in column_list:\n",
    "        for item in sublist:\n",
    "            columns.append(item) \n",
    "        \n",
    "    columns = set(columns)            \n",
    "    dict_list = []\n",
    "        \n",
    "    #valores em cada coluna\n",
    "    for index, row in df.iterrows():\n",
    "        content_words = row['CONTENT']\n",
    "        \n",
    "        bag_of_words_dict = {}       \n",
    "        for c in columns:\n",
    "            bag_of_words_dict[c] = 0\n",
    "        \n",
    "        for w in content_words:\n",
    "            if treatment_type == 'occurrency':\n",
    "                bag_of_words_dict[w] = 1\n",
    "            if treatment_type == 'frequency':\n",
    "                bag_of_words_dict[w] += 1\n",
    "            if treatment_type == 'tf-idf':         \n",
    "                bag_of_words_dict[w] +=1\n",
    "                \n",
    "        if treatment_type == 'tf-idf': \n",
    "            for w in bag_of_words_dict:\n",
    "                bag_of_words_dict[w] = bag_of_words_dict[w] / len(content_words)\n",
    "        \n",
    "        dict_list.append(bag_of_words_dict)        \n",
    "     \n",
    "    df = df.assign(bag_words=dict_list)\n",
    "    bag_words = df['bag_words'].apply(pd.Series)\n",
    "    \n",
    "    if treatment_type == 'tf-idf':\n",
    "        for c in bag_words:\n",
    "            if bag_words[c].sum() > 0:\n",
    "                bag_words[c] = np.log(len(df)/bag_words[c].sum())*bag_words[c]\n",
    "            else:\n",
    "                bag_words[c] = 0\n",
    "        \n",
    "    df = pd.concat([df, bag_words], axis = 1)\n",
    "    \n",
    "    #remover coluna content\n",
    "    df.drop(['CONTENT','bag_words'], axis=1, inplace=True)\n",
    "    #remover possiveis nulos\n",
    "    df.dropna(inplace=True)\n",
    "     \n",
    "    return df, columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_treated, columns = trata_dados(df_start, treatment_type='occurrency')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CLASS</th>\n",
       "      <th>comment_year</th>\n",
       "      <th>comment_hour</th>\n",
       "      <th>comment_len</th>\n",
       "      <th>sin_time</th>\n",
       "      <th>cos_time</th>\n",
       "      <th>origin_emi</th>\n",
       "      <th>origin_kat</th>\n",
       "      <th>origin_lma</th>\n",
       "      <th>origin_psy</th>\n",
       "      <th>...</th>\n",
       "      <th>screw</th>\n",
       "      <th>society</th>\n",
       "      <th>sexy</th>\n",
       "      <th>subscribeeeeeeeeee</th>\n",
       "      <th>courtthanks</th>\n",
       "      <th>briefs</th>\n",
       "      <th>low</th>\n",
       "      <th>china</th>\n",
       "      <th>httpenprothomalocomsportnewszibabweateamdueindhakawednesday</th>\n",
       "      <th>man</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>56</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>6.123234e-17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>166</td>\n",
       "      <td>1.224647e-16</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>38</td>\n",
       "      <td>-9.659258e-01</td>\n",
       "      <td>-2.588190e-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>48</td>\n",
       "      <td>8.660254e-01</td>\n",
       "      <td>-5.000000e-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>39</td>\n",
       "      <td>-8.660254e-01</td>\n",
       "      <td>-5.000000e-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 3907 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   CLASS  comment_year  comment_hour  comment_len      sin_time      cos_time  \\\n",
       "0      1        2013.0           6.0           56  1.000000e+00  6.123234e-17   \n",
       "1      1        2013.0          12.0          166  1.224647e-16 -1.000000e+00   \n",
       "2      1        2013.0          17.0           38 -9.659258e-01 -2.588190e-01   \n",
       "3      1        2013.0           8.0           48  8.660254e-01 -5.000000e-01   \n",
       "4      1        2013.0          16.0           39 -8.660254e-01 -5.000000e-01   \n",
       "\n",
       "   origin_emi  origin_kat  origin_lma  origin_psy ...   screw  society  sexy  \\\n",
       "0           0           0           0           1 ...       0        0     0   \n",
       "1           0           0           0           1 ...       0        0     0   \n",
       "2           0           0           0           1 ...       0        0     0   \n",
       "3           0           0           0           1 ...       0        0     1   \n",
       "4           0           0           0           1 ...       0        0     0   \n",
       "\n",
       "   subscribeeeeeeeeee  courtthanks  briefs  low  china  \\\n",
       "0                   0            0       0    0      0   \n",
       "1                   0            0       0    0      0   \n",
       "2                   0            0       0    0      0   \n",
       "3                   0            0       0    0      0   \n",
       "4                   0            0       0    0      0   \n",
       "\n",
       "   httpenprothomalocomsportnewszibabweateamdueindhakawednesday  man  \n",
       "0                                                  0              0  \n",
       "1                                                  0              0  \n",
       "2                                                  0              0  \n",
       "3                                                  0              0  \n",
       "4                                                  0              0  \n",
       "\n",
       "[5 rows x 3907 columns]"
      ]
     },
     "execution_count": 471,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_treated.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_treated.drop('CLASS', axis=1)\n",
    "Y = df_treated['CLASS']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo Escolhido para implementação : Support Vector Machines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funções auxiliares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_Y(y):\n",
    "    return np.array(y.values.flatten(), dtype = int)\n",
    "\n",
    "def min_max_scaler(x, scaler = None):\n",
    "    if scaler == None:\n",
    "        x_scaler = [x.min(), x.max()]\n",
    "        x_scaled = (x - x.min()) / (x.max() - x.min())\n",
    "        x_scaled.fillna(0, inplace = True)\n",
    "        return x_scaler, x_scaled\n",
    "    else:\n",
    "        x_scaled = (x - scaler[0]) / (scaler[1] - scaler[0]).replace(0, np.inf)\n",
    "        x_scaled = x_scaled.replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "        return x_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Occurency: C=3.000, gamma=0.100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_prep = prep_Y(Y)\n",
    "\n",
    "scaler, X_scaled = min_max_scaler(X)\n",
    "X_scaled_v = X_scaled.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [],
   "source": [
    "custo = 3\n",
    "gamma = 0.1\n",
    "kernel = 2\n",
    "\n",
    "model = svm_train(Y_prep, X_scaled_v, '-c %f -t %d -g %f' %(custo, kernel, gamma))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparação de um dado de entrada novo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COMMENT_ID</th>\n",
       "      <th>AUTHOR</th>\n",
       "      <th>DATE</th>\n",
       "      <th>CONTENT</th>\n",
       "      <th>origin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vbcido mxnoinicn</td>\n",
       "      <td>Priscila Portela</td>\n",
       "      <td>2013-11-07T06:20:48</td>\n",
       "      <td>check out my youtube channel subscribe pls</td>\n",
       "      <td>psy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         COMMENT_ID            AUTHOR                 DATE  \\\n",
       "0  vbcido mxnoinicn  Priscila Portela  2013-11-07T06:20:48   \n",
       "\n",
       "                                      CONTENT origin  \n",
       "0  check out my youtube channel subscribe pls    psy  "
      ]
     },
     "execution_count": 495,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_row = {\n",
    "    'COMMENT_ID': ['vbcido mxnoinicn'],\n",
    "    'AUTHOR': ['Priscila Portela'],\n",
    "    'DATE': ['2013-11-07T06:20:48'],\n",
    "    #'CONTENT': ['Hey guys check out my new channel'], #SPAM\n",
    "    #'CONTENT': ['free money www'], #SPAM\n",
    "    #'CONTENT': ['GOOD MUSIC'], #HAM\n",
    "    'CONTENT': ['check out my youtube channel subscribe pls'], #SPAM\n",
    "    #'CONTENT': ['check http'], #SPAM\n",
    "    #'CONTENT' : ['i love this song'], #HAM\n",
    "    'origin': 'psy'\n",
    "}\n",
    "\n",
    "predict_row = pd.DataFrame.from_dict(predict_row, orient='columns')\n",
    "predict_row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tratamento do dado de entrada novo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [],
   "source": [
    "#criação de novas colunas: ano, data e has_date (booleana, para o caso do dataset do eminem)\n",
    "predict_row['DATE'] = pd.to_datetime(predict_row['DATE'],infer_datetime_format=True)\n",
    "predict_row['comment_year'] = predict_row['DATE'].dt.year\n",
    "predict_row['comment_hour'] = predict_row['DATE'].dt.hour\n",
    "predict_row['comment_len'] = predict_row['CONTENT'].str.len()\n",
    "\n",
    "#apagar colunas\n",
    "predict_row.drop(['COMMENT_ID'], axis=1, inplace=True)\n",
    "predict_row.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUTHOR</th>\n",
       "      <th>DATE</th>\n",
       "      <th>CONTENT</th>\n",
       "      <th>origin</th>\n",
       "      <th>comment_year</th>\n",
       "      <th>comment_hour</th>\n",
       "      <th>comment_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Priscila Portela</td>\n",
       "      <td>2013-11-07 06:20:48</td>\n",
       "      <td>check out my youtube channel subscribe pls</td>\n",
       "      <td>psy</td>\n",
       "      <td>2013</td>\n",
       "      <td>6</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             AUTHOR                DATE  \\\n",
       "0  Priscila Portela 2013-11-07 06:20:48   \n",
       "\n",
       "                                      CONTENT origin  comment_year  \\\n",
       "0  check out my youtube channel subscribe pls    psy          2013   \n",
       "\n",
       "   comment_hour  comment_len  \n",
       "0             6           42  "
      ]
     },
     "execution_count": 497,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_row.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trata_dados_novos(df, treatment_type):\n",
    "    \n",
    "    #transformação trigonometrica da coluna hour\n",
    "    df['sin_time'] = np.sin(2*np.pi*df['comment_hour']/24)\n",
    "    df['cos_time'] = np.cos(2*np.pi*df['comment_hour']/24)\n",
    "        \n",
    "    df['origin_emi'] = 0\n",
    "    df['origin_kat'] = 0\n",
    "    df['origin_lma'] = 0\n",
    "    df['origin_psy'] = 0\n",
    "    df['origin_sha'] = 0\n",
    "        \n",
    "    if df['origin'][0] == 'emi':\n",
    "         df['origin_emi'] = 1            \n",
    "    if df['origin'][0] == 'kat':\n",
    "         df['origin_kat'] = 1\n",
    "    if df['origin'][0] == 'lma':\n",
    "         df['origin_lma'] = 1           \n",
    "    if df['origin'][0] == 'psy':\n",
    "         df['origin_psy'] = 1\n",
    "    if df['origin'][0] == 'sha':\n",
    "         df['origin_sha'] = 1\n",
    "    \n",
    "    df['has_date'] = np.where(df['comment_year'] == 1969, False, True)    \n",
    "    df.drop(['origin', 'DATE'], axis=1, inplace=True)\n",
    "        \n",
    "    #novas feature\n",
    "    df['has_www'] = df['CONTENT'].str.contains(pat = 'www') \n",
    "    df['has_http'] = df['CONTENT'].str.contains(pat = 'http')\n",
    "    df['has_link'] = df['CONTENT'].str.contains(pat = 'watch\\?v=')   \n",
    "    df['has_website'] = (df['has_www'] == True) | (df['has_http'] == True) | (df['has_link'] == True)\n",
    "    \n",
    "    #tratamento de texto\n",
    "    df.drop('AUTHOR', axis=1, inplace=True)\n",
    "    df['CONTENT'] = df['CONTENT'].str.lower()\n",
    "    \n",
    "    column_list = []\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        content = row['CONTENT']\n",
    "        \n",
    "        #retirar emojis e caracteres especiais\n",
    "        regular_characters = \"abcdefghijklmnopqrstuvwxyz \" \n",
    "        content = ''.join(c for c in content if c in regular_characters)\n",
    "        \n",
    "        #transfoma texto em lista de palavras:\n",
    "        content = content.split()\n",
    "                \n",
    "        #substituir contracoes de palavras\n",
    "        for k, v in word_dict.items():\n",
    "            content = [c.replace(k, v) for c in content]\n",
    "        \n",
    "        #remover stop words\n",
    "        for sw in stop_words:\n",
    "            content = [c for c in content if sw != c]\n",
    "        \n",
    "        column_list.append(content)\n",
    "        \n",
    "    column_list = [word for word in column_list if len(word) > 0]\n",
    " \n",
    "    df['CONTENT'] = pd.Series(column_list)\n",
    "    \n",
    "    df.dropna(axis=0, subset=['CONTENT'], inplace=True)\n",
    "    df = df[df['CONTENT'] != '[]']\n",
    "             \n",
    "    dict_list = []\n",
    "        \n",
    "    #valores em cada coluna\n",
    "    for index, row in df.iterrows():\n",
    "        content_words = row['CONTENT']\n",
    "        content_words = [x for x in content_words if x in columns]\n",
    "        \n",
    "        bag_of_words_dict = {}       \n",
    "        for c in columns:\n",
    "            bag_of_words_dict[c] = 0\n",
    "                 \n",
    "        for w in content_words:\n",
    "            if treatment_type == 'occurrency':\n",
    "                bag_of_words_dict[w] = 1\n",
    "        \n",
    "        dict_list.append(bag_of_words_dict)        \n",
    "     \n",
    "    df = df.assign(bag_words=dict_list)\n",
    "    bag_words = df['bag_words'].apply(pd.Series)\n",
    "        \n",
    "    df = pd.concat([df, bag_words], axis = 1)\n",
    "    \n",
    "    #remover coluna content\n",
    "    df.drop(['CONTENT','bag_words'], axis=1, inplace=True)\n",
    "    #remover possiveis nulos\n",
    "    df.dropna(inplace=True)\n",
    "    df.fillna(0, inplace=True)\n",
    "     \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_treated = trata_dados_novos(predict_row, 'occurrency')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_year</th>\n",
       "      <th>comment_hour</th>\n",
       "      <th>comment_len</th>\n",
       "      <th>sin_time</th>\n",
       "      <th>cos_time</th>\n",
       "      <th>origin_emi</th>\n",
       "      <th>origin_kat</th>\n",
       "      <th>origin_lma</th>\n",
       "      <th>origin_psy</th>\n",
       "      <th>origin_sha</th>\n",
       "      <th>...</th>\n",
       "      <th>screw</th>\n",
       "      <th>society</th>\n",
       "      <th>sexy</th>\n",
       "      <th>subscribeeeeeeeeee</th>\n",
       "      <th>courtthanks</th>\n",
       "      <th>briefs</th>\n",
       "      <th>low</th>\n",
       "      <th>china</th>\n",
       "      <th>httpenprothomalocomsportnewszibabweateamdueindhakawednesday</th>\n",
       "      <th>man</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013</td>\n",
       "      <td>6</td>\n",
       "      <td>42</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.123234e-17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 3906 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   comment_year  comment_hour  comment_len  sin_time      cos_time  \\\n",
       "0          2013             6           42       1.0  6.123234e-17   \n",
       "\n",
       "   origin_emi  origin_kat  origin_lma  origin_psy  origin_sha ...   screw  \\\n",
       "0           0           0           0           1           0 ...       0   \n",
       "\n",
       "   society  sexy  subscribeeeeeeeeee  courtthanks  briefs  low  china  \\\n",
       "0        0     0                   0            0       0    0      0   \n",
       "\n",
       "   httpenprothomalocomsportnewszibabweateamdueindhakawednesday  man  \n",
       "0                                                  0              0  \n",
       "\n",
       "[1 rows x 3906 columns]"
      ]
     },
     "execution_count": 500,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row_treated.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, o dado de entrada `row_treated` possui as mesmas colunas, na mesma ordem, do conjunto de dados que treinou o modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predição do dado novo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_treated_scaled = min_max_scaler(np.array(row_treated.values.flatten(), dtype = float), scaler).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_new_data(x, model, scaler = None):\n",
    "    if scaler:\n",
    "        x = min_max_scaler(np.array(row_treated.values.flatten(), dtype = float), scaler).values\n",
    "    xclass = svm_predict([], [x], model, options = '-q')[0][0]\n",
    "    print('O comentário é classificado como {}.'.format('SPAM' if xclass else 'HAM'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O comentário é classificado como SPAM.\n"
     ]
    }
   ],
   "source": [
    "test_new_data(row_treated_scaled, model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
